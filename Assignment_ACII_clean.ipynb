{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6e74d91f",
      "metadata": {},
      "source": [
        "# Urban Sound Classification: Deep Learning Approaches for Audio Recognition\n",
        "## Machine Learning II\n",
        "#### Work assembled by Beatriz Pereira, Carolina Leite, Lara Gonçalves"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "705dd6cd",
      "metadata": {},
      "source": [
        "### Table of contents <a name=\"contents\"></a>\n",
        "1. [Introduction](#introduction)\n",
        "2. [Data Understanding](#data-understanding)\n",
        "3. [Data Reading](#data-reading)\n",
        "    - 3.1. [Feature Extraction](#feature-extraction)\n",
        "    - 3.2. [Data Cleaning](#data-cleaning)\n",
        "      \n",
        "      - 3.2.1. [Reading](#reading)\n",
        "      \n",
        "      - 3.2.2. [Cleaning](#cleaning)\n",
        "     \n",
        "4. [Modeling](#modeling)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5dd2a9d",
      "metadata": {},
      "source": [
        "## 1. Introduction <a name=\"introduction\"></a>\n",
        "[[go back to the top]](#contents)\n",
        "\n",
        "The objective of this project is to develop **deep learning classifiers** for urban sound data. In this assignment, we will implement two of the three classifiers provided by the professor, as outlined in the [[PDF]](AC2_Project_20252026.pdf). \n",
        "\n",
        "The classifiers are:\n",
        "\n",
        "• A classifier based on a multilayer perceptron (MLP)\n",
        "\n",
        "• A classifier based on a convolutional neural network (CNN)\n",
        "\n",
        "• A classifier based on a recurrent neural network (RNN)\n",
        "\n",
        "And for each of the chosen classifier, the implementation will need to consider the following steps:\n",
        "1. Data pre-processing and preparation\n",
        "2. Model architecture definition\n",
        "3. Training strategies\n",
        "4. Performance evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3d95892",
      "metadata": {},
      "source": [
        "## 2. Data Understanding <a name=\"data-understanding\"></a>\n",
        "[[go back to the top]](#contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b34ea682",
      "metadata": {},
      "source": [
        "The dataset consists of 8,732 labeled sound excerpts, each lasting up to 4 seconds, categorized into 10 distinct classes:\n",
        "- air_conditioner [0] \n",
        "- car_horn [1] \n",
        "- children_playing [2] \n",
        "- dog_bark [3] \n",
        "- drilling [4] \n",
        "- enginge_idling [5] \n",
        "- gun_shot [6] \n",
        "- jackhammer [7] \n",
        "- siren [8] \n",
        "- street_music [9] "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb21d24f",
      "metadata": {},
      "source": [
        "The sound classes in the UrbanSound and UrbanSound8K datasets are derived from the UrbanSound taxonomy, as presented on the https://urbansounddataset.weebly.com/taxonomy.html\n",
        "\n",
        "Below is an image showcasing the taxonomy structure from the referenced site:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77d7f3ec",
      "metadata": {},
      "source": [
        "![Urban_Sound_Taxonomy](./images/urban_sound_taxonomy.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89237b78",
      "metadata": {},
      "source": [
        "All audio excerpts are derived from field recordings uploaded to http://www.freesound.org/\n",
        "\n",
        "The dataset comprises 8,732 urban sound audio files in WAV format. The sampling rate, bit depth, and number of channels correspond to those of the original files uploaded to Freesound, which may vary across different recordings.\n",
        "\n",
        "In addition to the audio excerpts, a CSV file containing metadata for each excerpt is also included.\n",
        "\n",
        "This is a short explanation of the csv:\n",
        "\n",
        "| Name of the Column | Brief Explanation                                                                                       |\n",
        "|--------------------|--------------------------------------------------------------------------------------------------------|\n",
        "| slice_file_name    | The name of the audio file, formatted as [fsID]-[classID]-[occurrenceID]-[sliceID].wav.              |\n",
        "| fsID               | The Freesound ID of the recording from which this excerpt (slice) is taken.                           |\n",
        "| start              | The start time of the slice in the original Freesound recording.                                      |\n",
        "| end                | The end time of the slice in the original Freesound recording.                                        |\n",
        "| salience           | A subjective salience rating of the sound (1 = foreground, 2 = background).                           |\n",
        "| fold               | The fold number (1-10) to which this file has been allocated.                                         |\n",
        "| classID            | A numeric identifier of the sound class (0-9) as listed above.                                        |\n",
        "| [occurrenceID]     | A numeric identifier to distinguish different occurrences of the sound within the original recording. |\n",
        "| [sliceID]          | A numeric identifier to distinguish different slices taken from the same occurrence.                 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05d4c67a",
      "metadata": {},
      "source": [
        "**To avoid common pitfalls**:\n",
        "-  Don't reshuffle the data! Use the predefined 10 folds and perform 10-fold (not 5-fold) cross validation\n",
        "-  Don't evaluate just on one split! Use 10-fold (not 5-fold) cross validation and average the scores"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5456a18",
      "metadata": {},
      "source": [
        "## 3. Data Reading <a name=\"data-reading\"></a>\n",
        "[[go back to the top]](#contents)\n",
        "\n",
        "\n",
        "After carefully analyzing the three available classifiers, we decided to implement CNN and RNN for this project. Our decision was based on several important considerations, which we have outlined in detail in the following [[Summary]](Research/Summary.md).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad56c475",
      "metadata": {},
      "source": [
        "### Librosa vs Scipy.io"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0a2694c",
      "metadata": {},
      "source": [
        "**Librosa:** is a library specialized in audio analysis and manipulation for machine learning and digital signal processing. It provides a wide range of tools aimed at feature extraction and audio representations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40022717",
      "metadata": {},
      "source": [
        "- Pros:\n",
        "    - Supports various audio formats (.wav, .mp3, etc.).\n",
        "    - Advanced feature extraction: Mel Spectrograms, MFCCs, Chromagrams.\n",
        "    - Easy audio manipulation (resampling, padding, normalization).\n",
        "    - Integration with visualizations (spectrograms, MFCCs).\n",
        "\n",
        "- Cons:\n",
        "    - Slower for simple tasks (loading/saving audio).\n",
        "    - Steeper learning curve for beginners.\n",
        "    - Depends on external libraries (audioread, ffmpeg)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbe10d62",
      "metadata": {},
      "source": [
        "**Scipy.io:** is part of the SciPy library and is a simple and efficient tool for reading and writing .wav files. It is useful for basic audio manipulation tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb04e4d6",
      "metadata": {},
      "source": [
        "- Pros:\n",
        "    - Simple, fast, and efficient for loading/saving .wav files.\n",
        "    - Direct integration with NumPy for basic manipulation.\n",
        "\n",
        "- Cons:\n",
        "    - Limited to .wav files.\n",
        "    - Does not support advanced feature degradation.\n",
        "    - Does not offer resampling, padding, or integrated views."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eed2959",
      "metadata": {},
      "source": [
        "Let's briefly analyze the differences between librosa and scipy.io."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3e749085",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "34dd530a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import librosa\n",
        "import scipy.io.wavfile as wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "83691a1c",
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = r\"UrbanSound8K/audio/fold1/7061-6-0-0.wav\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "8b96ccda",
      "metadata": {},
      "outputs": [],
      "source": [
        "librosa_audio, librosa_sample_rate = librosa.load(filename)\n",
        "scipy_sample_rate, scipy_audio = wav.read(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "01fc3618",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Librosa sample wave rate:\", librosa_sample_rate)\n",
        "print(\"Scipy sample wave rate : \" , scipy_sample_rate )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "f06b0e2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Librosa audio signal \" , librosa_audio)\n",
        "print(\"Librosa audio data type:\", librosa_audio.dtype)\n",
        "print()\n",
        "print(\"Scipy audio signal\" , scipy_audio)\n",
        "print(\"Scipy audio data type:\", scipy_audio.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "f5c30093",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(14, 8))  # Ajuste o tamanho da figura para mais altura\n",
        "\n",
        "# Plot librosa mono waveform\n",
        "plt.subplot(3, 1, 1)\n",
        "librosa.display.waveshow(librosa_audio, sr=librosa_sample_rate)\n",
        "plt.title(\"Librosa - Mono Waveform\")\n",
        "\n",
        "# Plot scipy stereo waveform (each channel separately if stereo)\n",
        "# Plot left and right channels in separate subplots\n",
        "plt.subplot(3, 1, 2)\n",
        "if scipy_audio.ndim > 1:  # Stereo\n",
        "    plt.plot(scipy_audio[:, 0], label=\"Left Channel\", color='blue')\n",
        "    plt.title(\"Scipy - Left Channel\")\n",
        "\n",
        "    plt.subplot(3, 1, 3)\n",
        "    plt.plot(scipy_audio[:, 1], label=\"Right Channel\", color='orange')\n",
        "    plt.title(\"Scipy - Right Channel\")\n",
        "else:  # Mono\n",
        "    plt.plot(scipy_audio)\n",
        "    plt.title(\"Scipy - Mono Waveform\")\n",
        "\n",
        "# Ajustar o layout para evitar sobreposição\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eb3bb3e",
      "metadata": {},
      "source": [
        "Taking into account all the pros and cons previously mentioned, we decided that for this work **we will use librosa**, as it offers more advantages for this type of project. Furthermore, it allows, by default, converting all audio to a sampling rate of 22050 Hz (normally used in audio learning and processing models), converting audio into a single signal (mono sound), and also normalizing audio, unlike scipy, which converts audio into arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c10e7586",
      "metadata": {},
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "01e48979",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import librosa\n",
        "import os\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import scipy.stats\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "472314be",
      "metadata": {},
      "outputs": [],
      "source": [
        "path_csv = 'UrbanSound8K/metadata/UrbanSound8K.csv'\n",
        "\n",
        "df = pd.read_csv(path_csv)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d64ae4e6",
      "metadata": {},
      "source": [
        "##### Check if there's any missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "a7098317",
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing values per column:\")\n",
        "print(missing_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7958f8d",
      "metadata": {},
      "source": [
        "As we can see, the dataset **does not contain any null values**, which is great considering that this means there is no missing data, and therefore it is possible to know the correct classification of each audio file."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27042eb1",
      "metadata": {},
      "source": [
        "##### Check if there's any duplicate values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "91892758",
      "metadata": {},
      "outputs": [],
      "source": [
        "duplicates = df.duplicated()\n",
        "print(f\"Duplicates values: {duplicates.sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07ce5722",
      "metadata": {},
      "source": [
        "There are also **no duplicate values**, meaning that each audio file in the dataset, even if it comes from the same original FreeSound audio, is not identical to any other, as it corresponds to different slices within the audio."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef07a159",
      "metadata": {},
      "source": [
        "##### Data Consistency"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01c7dc67",
      "metadata": {},
      "source": [
        "Although there appear to be no problems with the data, according to the audio metadata, we need to confirm if, for any reason, there is a file listed in the metadata that does not appear in the audio directory, or if there is any audio that does not appear in the metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "4ffbaef6",
      "metadata": {},
      "outputs": [],
      "source": [
        "audios_dir = r\"UrbanSound8K\\audio\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0d07f0e",
      "metadata": {},
      "source": [
        "Let's start by testing if all the audio files described in the metadata are located in the correct folders:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "be02e96b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize list of missing files\n",
        "missing_files = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    # Build the expected file path\n",
        "    fold = row['fold']\n",
        "    folder_name = \"fold\" + str(fold)\n",
        "    file_name = row['slice_file_name']\n",
        "    file_path = os.path.join(audios_dir, folder_name, file_name)\n",
        "    \n",
        "    # Check if file exists\n",
        "    if not os.path.isfile(file_path):\n",
        "        missing_files.append(file_path)\n",
        "\n",
        "# Show missing files\n",
        "if missing_files:\n",
        "    print(f\"Missing files ({len(missing_files)}):\")\n",
        "    for file in missing_files:\n",
        "        print(file)\n",
        "else:\n",
        "    print(\"All files are present.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fe1df25",
      "metadata": {},
      "source": [
        "Now, let's check if there are any extra files in the different folds:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "e7421cd4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize list of extra files\n",
        "extra_files = []\n",
        "\n",
        "for fold in range(1, 11):  # Folders 1 to 10\n",
        "    folder_name = \"folder\" + str(fold)\n",
        "    folder_path = os.path.join(audios_dir, folder_name)\n",
        "    if os.path.exists(folder_path):\n",
        "        # List all files in folder\n",
        "        files_in_folder = os.listdir(folder_path)\n",
        "        # Filter only audio files\n",
        "        audio_files = [f for f in files_in_folder if f.endswith('.wav')]\n",
        "        \n",
        "        # Compare with files listed in CSV\n",
        "        expected_files = df[df['fold'] == fold]['slice_file_name'].tolist()\n",
        "        for audio_file in audio_files:\n",
        "            if audio_file not in expected_files:\n",
        "                extra_files.append(os.path.join(folder_path, audio_file))\n",
        "\n",
        "# Show extra files\n",
        "if extra_files:\n",
        "    print(f\"Extra files ({len(extra_files)}):\")\n",
        "    for file in extra_files:\n",
        "        print(file)\n",
        "else:\n",
        "    print(\"No extra files found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "346efd1f",
      "metadata": {},
      "source": [
        "As we can see, there are no inconsistencies between the data described in the metadata and the audio files we have. We can therefore proceed to a more detailed analysis of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "a911c391",
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = sns.histplot(y='class',data = df, hue=\"class\", multiple=\"stack\")\n",
        "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
        "plt.xticks(rotation=45)\n",
        "sns.despine()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "01002741",
      "metadata": {},
      "outputs": [],
      "source": [
        "class_dict = df['class'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "13703e2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "class_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "943500f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = class_dict.index\n",
        "values = class_dict.values\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_title('Class Distribution', y=1.08, fontsize=18)\n",
        "ax.pie(values, labels=classes, autopct='%1.1f%%', shadow=False, startangle=180)\n",
        "ax.axis('equal')\n",
        "plt.show(block=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9672260e",
      "metadata": {},
      "source": [
        "Although the **'car_horn'** and **'gun_shot'** classes have fewer entries, and therefore fewer audio files of those types, the dataset appears to be minimally balanced, so no changes are necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "af23fc21",
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Create the figure and subplots\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 12))\n",
        "\n",
        "# Color palette\n",
        "palette = sns.color_palette(\"tab10\")\n",
        "\n",
        "# First graphic: Countplot\n",
        "sns.countplot(\n",
        "    data=df, \n",
        "    x='fold', \n",
        "    hue='class', \n",
        "    palette=palette, \n",
        "    ax=axes[0]\n",
        ")\n",
        "axes[0].set_title('Class Distribution by Fold', fontsize=16)\n",
        "axes[0].set_xlabel('Fold', fontsize=12)\n",
        "axes[0].set_ylabel('Number of examples', fontsize=12)\n",
        "axes[0].legend(title='Classes', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Count number of examples of each class by fold\n",
        "class_fold_distribution = df.groupby(['fold', 'class']).size().unstack(fill_value=0)\n",
        "\n",
        "# Second graphics: Stacked bars\n",
        "class_fold_distribution.plot(\n",
        "    kind='bar', \n",
        "    stacked=True, \n",
        "    colormap='tab10',\n",
        "    ax=axes[1]\n",
        ")\n",
        "axes[1].set_title('Class Distribution by Fold (Stacked)', fontsize=16)\n",
        "axes[1].set_xlabel('Fold', fontsize=12)\n",
        "axes[1].set_ylabel('Number of Examples', fontsize=12)\n",
        "axes[1].legend(title='Classes', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Adjust layout to avoid overlap\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "5673a3ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "appended = []\n",
        "for i in range(1,11):\n",
        "    appended.append(df[df.fold == i]['class'].value_counts())\n",
        "    \n",
        "class_distribution = pd.DataFrame(appended)\n",
        "class_distribution = class_distribution.reset_index()\n",
        "class_distribution['index'] = [\"fold\"+str(x) for x in range(1,11)]\n",
        "class_distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0acbd6af",
      "metadata": {},
      "source": [
        "Although some classes have fewer entries than others, we can see that by fold the classes seem to be fairly evenly distributed, with approximately the same number of entries per class in each fold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "798dd4a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.countplot(data = df, x = 'salience')\n",
        "plt.title('Salience Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6a9f201",
      "metadata": {},
      "source": [
        "We concluded that most of the audio files are classified as having been obtained from 'foreground' sources."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27649398",
      "metadata": {},
      "source": [
        "##### Audio Duration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "a5679e96",
      "metadata": {},
      "outputs": [],
      "source": [
        "# List for storing durations\n",
        "durations = []\n",
        "\n",
        "# Process each audio\n",
        "for index, row in df.iterrows():\n",
        "    fold = row['fold']\n",
        "    fold_name = \"fold\" + str(fold)\n",
        "    file_name = row['slice_file_name']\n",
        "    file_path = os.path.join(audios_dir, fold_name, file_name)\n",
        "    \n",
        "    if os.path.isfile(file_path):\n",
        "        # Load audio\n",
        "        y, sr = librosa.load(file_path, sr=None)  # sr=None para manter a taxa original\n",
        "        # Get original duration\n",
        "        durations.append(librosa.get_duration(y=y, sr=sr))\n",
        "    else:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "\n",
        "# Show duration distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(durations, bins=20, color='teal', edgecolor='black')\n",
        "plt.title('Distribution of Audio Durations', fontsize=16)\n",
        "plt.xlabel('Duration (seconds)', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92d60a02",
      "metadata": {},
      "source": [
        "##### Accessing the audio data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "366c85ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Go through the 10 folds\n",
        "for fold in range(1, 11):\n",
        "    fold_path = os.path.join(audios_dir, f'fold{fold}')\n",
        "    \n",
        "    # Check if the folder path exists\n",
        "    if os.path.exists(fold_path):\n",
        "        # Browse the audio files within the fold\n",
        "        for file_name in os.listdir(fold_path):\n",
        "            if file_name.endswith('.wav'):\n",
        "                # Full path to the audio file\n",
        "                file_path = os.path.join(fold_path, file_name)\n",
        "                \n",
        "                # Upload audio using librosa\n",
        "                audio, sample_rate = librosa.load(file_path)\n",
        "                \n",
        "                # Example: Process audio or extract features\n",
        "                print(f\"File: {file_name}, Sample Rate: {sample_rate}, Duration: {len(audio)/sample_rate:.2f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76951d85",
      "metadata": {},
      "source": [
        "##### As observed, some audio clips have varying durations, such as 1.64, 2.61, and up to 4 seconds. To simplify the processing and ensure consistency, we will standardize all audio data to the same length. This allows for uniform input to our models, improving training efficiency and performance. How can we do that?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "268eb7df",
      "metadata": {},
      "source": [
        "##### Well, there's four strategies:\n",
        "- **Zeropadding:** Ideal for maintaining the integrity of short audios.\n",
        "- **Audio Repetition:** Works well for rhythmic or repetitive sounds.\n",
        "- **Discard Short Audios:** Simple and effective when you can afford to lose some data.\n",
        "- **Interpolation:** Suitable if you want to maintain consistency in the timing of the audio, but can change the way it sounds.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}